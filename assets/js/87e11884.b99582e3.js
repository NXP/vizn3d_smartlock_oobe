"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[60],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return m}});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=n.createContext({}),d=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},c=function(e){var t=d(e.components);return n.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},v=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),v=d(a),m=i,_=v["".concat(s,".").concat(m)]||v[m]||p[m]||o;return a?n.createElement(_,r(r({ref:t},c),{},{components:a})):n.createElement(_,r({ref:t},c))}));function m(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=a.length,r=new Array(o);r[0]=v;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:i,r[1]=l;for(var d=2;d<o;d++)r[d]=a[d];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}v.displayName="MDXCreateElement"},9709:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return d},toc:function(){return c},default:function(){return v}});var n=a(7462),i=a(3366),o=(a(7294),a(3905)),r=["components"],l={sidebar_position:6},s="VAlgo Devices",d={unversionedId:"framework/hal_devices/valgo",id:"framework/hal_devices/valgo",isDocsHomePage:!1,title:"VAlgo Devices",description:"The Vision Algorithm HAL device type represents an abstraction for computer vision algorithms which are used for analysis of digital images, videos, and other visual inputs.",source:"@site/docs/framework/hal_devices/valgo.md",sourceDirName:"framework/hal_devices",slug:"/framework/hal_devices/valgo",permalink:"/vizn3d_smartlock_oobe/docs/framework/hal_devices/valgo",tags:[],version:"current",sidebarPosition:6,frontMatter:{sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"Display Devices",permalink:"/vizn3d_smartlock_oobe/docs/framework/hal_devices/display"},next:{title:"Low Power Devices",permalink:"/vizn3d_smartlock_oobe/docs/framework/hal_devices/low_power"}},c=[{value:"Device Definition",id:"device-definition",children:[],level:2},{value:"Operators",id:"operators",children:[{value:"Init",id:"init",children:[],level:3},{value:"Deinit",id:"deinit",children:[],level:3},{value:"Run",id:"run",children:[],level:3},{value:"InputNotify",id:"inputnotify",children:[],level:3}],level:2},{value:"Capabilities",id:"capabilities",children:[{value:"callback",id:"callback",children:[],level:3},{value:"param",id:"param",children:[],level:3}],level:2},{value:"Private Data",id:"private-data",children:[{value:"autoStart",id:"autostart",children:[],level:3},{value:"frames",id:"frames",children:[],level:3}],level:2},{value:"Example",id:"example",children:[],level:2}],p={toc:c};function v(e){var t=e.components,a=(0,i.Z)(e,r);return(0,o.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"valgo-devices"},"VAlgo Devices"),(0,o.kt)("p",null,"The Vision Algorithm HAL device type represents an abstraction for computer vision algorithms which are used for analysis of digital images, videos, and other visual inputs."),(0,o.kt)("p",null,'The crux of the design for Vision Algorithm devices is centered around the use of "infer complete" events which communicate information about the results of inferencing which is handled by the device.\nFor example, in the Smart Lock application, the Vision Algorithm may receive a camera frame containing a recognized face,\nperform an inference on that data,\nand communicate a "face recognized" message to other devices so that they may act accordingly.\nFor more information about events and event handling, see ',(0,o.kt)("a",{parentName:"p",href:"/vizn3d_smartlock_oobe/docs/framework/events/overview"},"Events"),"."),(0,o.kt)("p",null,"Currently, only one vision algorithm device can be registered to the Vision Manager at a time per the design of the framework."),(0,o.kt)("h2",{id:"device-definition"},"Device Definition"),(0,o.kt)("p",null,"The HAL device definition for vision algorithm devices can be found under ",(0,o.kt)("inlineCode",{parentName:"p"},"framework/hal_api/hal_valgo_dev.h")," and is reproduced below:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c",metastring:'title="vision_algo_dev_t"',title:'"vision_algo_dev_t"'},"/*! @brief definition of a vision algo device */\ntypedef struct _vision_algo_dev\n{\n    /* unique id which is assigned by vision algorithm manager during the registration */\n    int id;\n    /* name to identify */\n    char name[DEVICE_NAME_MAX_LENGTH];\n    /* private capability */\n    valgo_dev_private_capability_t cap;\n    /* operations */\n    vision_algo_dev_operator_t *ops;\n    /* private data */\n    vision_algo_private_data_t data;\n} vision_algo_dev;\n")),(0,o.kt)("p",null,"The ",(0,o.kt)("a",{parentName:"p",href:"#operators"},"operators")," associated with the vision algo HAL device are as shown below:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"/*! @brief Operation that needs to be implemented by a vision algorithm device */\ntypedef struct\n{\n    /* initialize the dev */\n    hal_valgo_status_t (*init)(vision_algo_dev_t *dev, valgo_dev_callback_t callback, void *param);\n    /* deinitialize the dev */\n    hal_valgo_status_t (*deinit)(vision_algo_dev_t *dev);\n    /* run the inference */\n    hal_valgo_status_t (*run)(const vision_algo_dev_t *dev, void *data);\n    /* recv events */\n    hal_valgo_status_t (*inputNotify)(const vision_algo_dev_t *receiver, void *data);\n\n} vision_algo_dev_operator_t;\n")),(0,o.kt)("p",null,"The ",(0,o.kt)("a",{parentName:"p",href:"#capabilities"},"capabilities")," associated with the vision algo HAL device are as shown below:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"typedef struct _valgo_dev_private_capability\n{\n    /* callback */\n    valgo_dev_callback_t callback;\n    /* param for the callback */\n    void *param;\n} valgo_dev_private_capability_t;\n")),(0,o.kt)("p",null,"The ",(0,o.kt)("a",{parentName:"p",href:"#private-data"},"private data")," fields associated with the vision algo HAL device is as shown below:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"typedef struct\n{\n    int autoStart;\n    /* frame type definition */\n    vision_frame_t frames[kVAlgoFrameID_Count];\n} vision_algo_private_data_t;\n")),(0,o.kt)("h2",{id:"operators"},"Operators"),(0,o.kt)("p",null,'Operators are functions which "operate" on a HAL device itself.\nOperators are akin to "public methods" in object oriented-languages,\nand are used by the Vision Algorithm Manager to setup, start, etc. its registered vision algo device.'),(0,o.kt)("p",null,"For more information about operators, see ",(0,o.kt)("a",{parentName:"p",href:"/vizn3d_smartlock_oobe/docs/framework/hal_devices/overview#Operators"},"Operators"),"."),(0,o.kt)("h3",{id:"init"},"Init"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"hal_valgo_status_t (*init)(vision_algo_dev_t *dev, valgo_dev_callback_t callback, void *param);\n")),(0,o.kt)("p",null,"Init the vision algo HAL device."),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"Init")," should initialize any hardware resources the device requires (I/O ports, IRQs, etc.), turn on the hardware, and perform any other setup required by the device."),(0,o.kt)("p",null,"The ",(0,o.kt)("a",{parentName:"p",href:"#callback"},"callback function")," to the device's manager is typically installed as part of the ",(0,o.kt)("inlineCode",{parentName:"p"},"Init")," function as well."),(0,o.kt)("p",null,"This operator will be called by the vision algorithm manager when the output manager task first starts."),(0,o.kt)("h3",{id:"deinit"},"Deinit"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"hal_valgo_status_t (*deinit)(vision_algo_dev_t *dev);\n")),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"DeInit"),' function is used to "deinitialize" the algorithm device.\n',(0,o.kt)("inlineCode",{parentName:"p"},"DeInit")," should release any hardware resources the device uses (I/O ports, IRQs, etc.), turn off the hardware, and perform any other shutdown required by the device."),(0,o.kt)("p",null,"This operator will be called by the Vision Algorithm Manager when the Vision Algorithm Manager task ends",(0,o.kt)("sup",{parentName:"p",id:"fnref-1"},(0,o.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1")),"."),(0,o.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},(0,o.kt)("sup",{parentName:"p",id:"fnref-1"},(0,o.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1")),"The ",(0,o.kt)("inlineCode",{parentName:"p"},"DeInit")," function generally will not be called under normal operation."))),(0,o.kt)("h3",{id:"run"},"Run"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"hal_valgo_status_t (*run)(const voice_algo_dev_t *dev, void *data);\n")),(0,o.kt)("p",null,"Begin running the vision algorithm."),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"run")," operator is used to start running algorithm inference and processing camera frame data."),(0,o.kt)("p",null,'This operator is called by the Vision Algorithm manager when\na "camera frame ready" message is received from the Camera Manager and forwarded to the algorithm device via the Vision Algorithm Manager.'),(0,o.kt)("p",null,'Once the Vision Algorithm device finishes processing the camera frame data, its manager will forward this message to the Output Manager in the form of an "inference complete" message.'),(0,o.kt)("h3",{id:"inputnotify"},"InputNotify"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"hal_valgo_status_t (*inputNotify)(const vision_algo_dev_t *receiver, void *data);\n")),(0,o.kt)("p",null,"Handle input events."),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"InputNotify")," operator is called by the Vision Algorithm Manager whenever a ",(0,o.kt)("inlineCode",{parentName:"p"},"kFWKMessageID_InputNotify")," message is received and forwarded from the Vision Algorithm Manager's message queue."),(0,o.kt)("p",null,"For more information regarding events and event handling, see ",(0,o.kt)("a",{parentName:"p",href:"/vizn3d_smartlock_oobe/docs/framework/events/overview"},"Events"),"."),(0,o.kt)("h2",{id:"capabilities"},"Capabilities"),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"capabilities")," struct is primarily used for storing a callback to communicate information from the device back to the Vision Algorithm Manager.\nThis callback function is typically installed via a device's ",(0,o.kt)("inlineCode",{parentName:"p"},"init")," operator."),(0,o.kt)("h3",{id:"callback"},"callback"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c",metastring:'title="valgo_dev_callback_t"',title:'"valgo_dev_callback_t"'},"/*!\n * @brief Callback function to notify managers the results of inference\n * valgo_dev* dev Pointer to an algorithm device\n * valgo_event_t event Event which took place\n * void* param Pointer to a struct of data that needs to be forwarded\n * unsigned int size Size of the struct that needs to be forwarded. If size = 0, param should be a pointer to a\n * persistent memory area.\n */\n\ntypedef int (*valgo_dev_callback_t)(int devId, valgo_event_t event, void *param, unsigned int size, uint8_t fromISR);\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"valgo_dev_callback_t callback;\n")),(0,o.kt)("p",null,"Callback to the Vision Algorithm Manager."),(0,o.kt)("p",null,"The Vision Algorithm manager will provide the callback to the device when the ",(0,o.kt)("inlineCode",{parentName:"p"},"init")," operator is called.\nAs a result, the HAL device should make sure to store the callback in the ",(0,o.kt)("inlineCode",{parentName:"p"},"init")," operator's implementation."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c",metastring:'title="Example Vision Algorithm Device Init" {9-11}',title:'"Example',Vision:!0,Algorithm:!0,Device:!0,'Init"':!0,"{9-11}":!0},"static hal_valgo_status_t HAL_VisionAlgoDev_ExampleDev_Init(vision_algo_dev_t *dev,\n                                                           valgo_dev_callback_t callback,\n                                                           void *param)\n{\n    hal_valgo_status_t ret = kStatus_HAL_ValgoSuccess;\n\n    /* PERFORM INIT FUNCTIONALITY HERE */\n\n    ...\n\n    /* Installing callback function from manager... */\n    memset(&dev->cap, 0, sizeof(dev->cap));\n    dev->cap.callback = callback;\n\n    return ret;\n}\n")),(0,o.kt)("p",null,"The HAL device invokes this callback to notify the Vision Algorithm manager of specific events."),(0,o.kt)("h3",{id:"param"},"param"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"void *param;\n")),(0,o.kt)("p",null,"The param for the callback (optional)."),(0,o.kt)("h2",{id:"private-data"},"Private Data"),(0,o.kt)("h3",{id:"autostart"},"autoStart"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"int autoStart;\n")),(0,o.kt)("p",null,"The flag for automatically starting the algorithm."),(0,o.kt)("p",null,"If ",(0,o.kt)("inlineCode",{parentName:"p"},"autoStart")," is 1, the Vision Algorithm Manager will automatically start requesting camera frames for this algorithm device after its ",(0,o.kt)("inlineCode",{parentName:"p"},"init")," operator is executed."),(0,o.kt)("h3",{id:"frames"},"frames"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"vision_frame_t frames[kVAlgoFrameID_Count];\n")),(0,o.kt)("p",null,"The three kinds of frames which are currently supported by the vision framework are ",(0,o.kt)("inlineCode",{parentName:"p"},"RGB"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"IR")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"Depth")," images."),(0,o.kt)("p",null,"The vision algorithm device needs to specify information for each kind of frame,\nso that the framework will properly convert and pass only the frames which correspond to this algorithm device's requirement."),(0,o.kt)("p",null,"For example, the Smart Lock application uses both 3D Depth and IR camera images to perform liveness\ndetection and face recognition,\nwhile using RGB frames solely for use as user feedback to help with\naligning a user's face, etc.\nTherefore, the algorithm device needs to ensure that it is receiving only the 3D and IR frames and\nnot any RGB frames."),(0,o.kt)("p",null,"The definition of ",(0,o.kt)("inlineCode",{parentName:"p"},"vision_frame_t")," is as shown below:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},"typedef struct _vision_frame\n{\n    /* is supported by the device for this type of frame */\n    /* Vision Algorithm Manager will only request the supported frame for this device */\n    int is_supported;\n\n    /* frame resolution */\n    int height;\n    int width;\n    int pitch;\n\n    /* rotate degree */\n    cw_rotate_degree_t rotate;\n    flip_mode_t flip;\n    /* swap byte per two bytes */\n    int swapByte;\n\n    /* pixel format */\n    pixel_format_t format;\n\n    /* the source pixel format of the requested frame */\n    pixel_format_t srcFormat;\n    void *data;\n} vision_frame_t;\n")),(0,o.kt)("h2",{id:"example"},"Example"),(0,o.kt)("p",null,"Because only one Vision Algorithm device can be registered at a time per the design of the framework,\nthe SLN-VIZN3D-IOT Smart Lock project has one Vision Algorithm device implemented.",(0,o.kt)("sup",{parentName:"p",id:"fnref-2"},(0,o.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2"))),(0,o.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"info")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},(0,o.kt)("sup",{parentName:"p",id:"fnref-2"},(0,o.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),"This example is implemented using NXP's OasisLite face recognition algorithm,\nwhich is the core vision computing algorithm used in the SLN-VIZN3D-IOT Smart Lock project."))),(0,o.kt)("p",null,"This example is reproduced below:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-c"},'static hal_valgo_status_t HAL_VisionAlgoDev_OasisLite_Init(vision_algo_dev_t *dev,\n                                                           valgo_dev_callback_t callback,\n                                                           void *param);\nstatic hal_valgo_status_t HAL_VisionAlgoDev_OasisLite_Deinit(vision_algo_dev_t *dev);\nstatic hal_valgo_status_t HAL_VisionAlgoDev_OasisLite_Run(const vision_algo_dev_t *dev, void *data);\nstatic hal_valgo_status_t HAL_VisionAlgoDev_OasisLite_InputNotify(const vision_algo_dev_t *receiver, void *data);\n\n/* vision algorithm device operators */\nconst static vision_algo_dev_operator_t s_VisionAlgoDev_OasisLiteOps = {\n    .init        = HAL_VisionAlgoDev_OasisLite_Init,\n    .deinit      = HAL_VisionAlgoDev_OasisLite_Deinit,\n    .run         = HAL_VisionAlgoDev_OasisLite_Run,\n    .inputNotify = HAL_VisionAlgoDev_OasisLite_InputNotify,\n};\n\n/* vision algorithm device */\nstatic vision_algo_dev_t s_VisionAlgoDev_OasisLite3D = {\n    .id   = 0,\n    .name = "OASIS_3D",\n    .ops  = (vision_algo_dev_operator_t *)&s_VisionAlgoDev_OasisLiteOps,\n    .cap  = {.param = NULL},\n};\n\n/* vision algorithm device Init function*/\nstatic hal_valgo_status_t HAL_VisionAlgoDev_OasisLite_Init(vision_algo_dev_t *dev,\n                                                           valgo_dev_callback_t callback,\n                                                           void *param)\n{\n    LOGI("++HAL_VisionAlgoDev_OasisLite_Init");\n    hal_valgo_status_t ret = kStatus_HAL_ValgoSuccess;\n\n    // init the device\n    memset(&dev->cap, 0, sizeof(dev->cap));\n    dev->cap.callback = callback;\n\n    /* set parameters of the requested frames that this vision algorithm dev asks for*/\n    /* for example oasisLite algorithm asks for two kind of frames: one is IR, the other is Depth */\n    /* firstly set parameters of the requested IR frames */\n    dev->data.autoStart                             = 1;\n    dev->data.frames[kVAlgoFrameID_IR].height       = OASIS_FRAME_HEIGHT;\n    dev->data.frames[kVAlgoFrameID_IR].width        = OASIS_FRAME_WIDTH;\n    dev->data.frames[kVAlgoFrameID_IR].pitch        = OASIS_FRAME_WIDTH * 3;\n    dev->data.frames[kVAlgoFrameID_IR].is_supported = 1;\n    dev->data.frames[kVAlgoFrameID_IR].rotate       = kCWRotateDegree_0;\n    dev->data.frames[kVAlgoFrameID_IR].flip         = kFlipMode_None;\n    dev->data.frames[kVAlgoFrameID_IR].format    = kPixelFormat_BGR;\n    dev->data.frames[kVAlgoFrameID_IR].srcFormat = kPixelFormat_Gray16;\n    int oasis_lite_rgb_frame_aligned_size        = SDK_SIZEALIGN(OASIS_FRAME_HEIGHT * OASIS_FRAME_WIDTH * 3, 64);\n    dev->data.frames[kVAlgoFrameID_IR].data      = pvPortMalloc(oasis_lite_rgb_frame_aligned_size);\n\n    if (dev->data.frames[kVAlgoFrameID_IR].data == NULL)\n    {\n        OASIS_LOGE("[ERROR]: Unable to allocate memory for kVAlgoFrameID_IR.");\n        ret = kStatus_HAL_ValgoMallocError;\n        return ret;\n    }\n    /* secondly set parameters of the requested Depth frames */\n    dev->data.frames[kVAlgoFrameID_Depth].height       = OASIS_FRAME_HEIGHT;\n    dev->data.frames[kVAlgoFrameID_Depth].width        = OASIS_FRAME_WIDTH;\n    dev->data.frames[kVAlgoFrameID_Depth].pitch        = OASIS_FRAME_WIDTH * 2;\n    dev->data.frames[kVAlgoFrameID_Depth].is_supported = 1;\n    dev->data.frames[kVAlgoFrameID_Depth].rotate       = kCWRotateDegree_0;\n    dev->data.frames[kVAlgoFrameID_Depth].flip         = kFlipMode_None;\n\n    dev->data.frames[kVAlgoFrameID_Depth].format    = kPixelFormat_Depth16;\n    dev->data.frames[kVAlgoFrameID_Depth].srcFormat = kPixelFormat_Depth16;\n    int oasis_lite_depth_frame_aligned_size         = SDK_SIZEALIGN(OASIS_FRAME_HEIGHT * OASIS_FRAME_WIDTH * 2, 64);\n    dev->data.frames[kVAlgoFrameID_Depth].data      = pvPortMalloc(oasis_lite_depth_frame_aligned_size);\n\n    if (dev->data.frames[kVAlgoFrameID_Depth].data == NULL)\n    {\n        OASIS_LOGE("Unable to allocate memory for kVAlgoFrameID_IR");\n        ret = kStatus_HAL_ValgoMallocError;\n        return ret;\n    }\n\n    /* do private Algorithm Init here */\n    ...\n\n    LOGI("--HAL_VisionAlgoDev_OasisLite_Init");\n    return ret;\n}\n\n/* vision algorithm device DeInit function*/\nstatic hal_valgo_status_t HAL_VisionAlgoDev_OasisLite_Deinit(vision_algo_dev_t *dev)\n{\n    hal_valgo_status_t ret = kStatus_HAL_ValgoSuccess;\n    LOGI("++HAL_VisionAlgoDev_OasisLite_Deinit");\n\n    /* release resource here */\n    ...\n\n    LOGI("--HAL_VisionAlgoDev_OasisLite_Deinit");\n    return ret;\n}\n\n/* vision algorithm device inference run function*/\nstatic hal_valgo_status_t HAL_VisionAlgoDev_OasisLite_Run(const vision_algo_dev_t *dev, void *data)\n{\n    hal_valgo_status_t ret = kStatus_HAL_ValgoSuccess;\n    OASIS_LOGI("++HAL_VisionAlgoDev_OasisLite_Run");\n\n    vision_algo_result_t result;\n    /* do inference run, derive meaningful information from the current frame data in dev private data */\n    /* for example, oasisLite will inference according to two kinds of input frames:\n       void* frame1 = dev->data.frames[kVAlgoFrameID_IR].data\n       void* frame2 = dev->data.frames[kVAlgoFrameID_Depth].data\n       result = oasisLite_run(frame1, frame2, ......);\n    */\n    ...\n\n    /* execute algorithm manager callback to inform algorithm manager the result */\n    if (dev != NULL && result != NULL && dev->cap.callback != NULL)\n    {\n        dev->cap.callback(dev->id, kVAlgoEvent_VisionResultUpdate, result, sizeof(vision_algo_result_t), 0);\n    }\n\n    OASIS_LOGI("--HAL_VisionAlgoDev_OasisLite_Run");\n    return ret;\n}\n\n/* vision algorithm device InputNotify function*/\nstatic hal_valgo_status_t HAL_VisionAlgoDev_OasisLite_InputNotify(const vision_algo_dev_t *receiver, void *data)\n{\n    hal_valgo_status_t ret = kStatus_HAL_ValgoSuccess;\n    OASIS_LOGI("++HAL_VisionAlgoDev_OasisLite_InputNotify");\n    event_base_t eventBase = *(event_base_t *)data;\n\n    /* do proess according to different input notify event */\n    ...\n\n    LOGI("--HAL_VisionAlgoDev_OasisLite_InputNotify");\n    return ret;\n}\n\n/* register vision algorithm device to vision algorithm manager */\nint HAL_VisionAlgoDev_OasisLite3D_Register()\n{\n    int error = 0;\n    LOGD("HAL_VisionAlgoDev_OasisLite3D_Register");\n    error = FWK_VisionAlgoManager_DeviceRegister(&s_VisionAlgoDev_OasisLite3D);\n\n    return error;\n}\n')))}v.isMDXComponent=!0}}]);